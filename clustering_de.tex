\documentclass[journal]{vgtc} 
\usepackage{hs-vis_ss10}


%% Please note that the use of figures other than the optional teaser
%% is not permitted on the first page of the journal version.  Figures
%% should begin on the second page and be in CMYK or Grey scale
%% format, otherwise, colour shifting may occur during the printing
%% process.  Papers submitted with figures other than the optional
%% teaser on the first page will be refused.

%% These three lines bring in essential packages: ``mathptmx'' for
%% Type 1 typefaces, ``graphicx'' for inclusion of EPS figures. and
%% ``times'' for proper handling of the times font family.

\usepackage{mathptmx} 
\usepackage{graphicx}
\usepackage{times}
\usepackage{amsmath}

%% allow for this line if you want the electronic option to work
%% properly
\vgtcinsertpkg


%% author name
\author{Moritz Hamann}

%% paper title
\title{Clustering of dynamic graphs}

%% short title for header
\shorttitle{Clustering of dynamic graphs}


%% Abstract section.
\abstract{%
This paper presents a summary about various techniques to detect and identify densely connected
nodes in a graph, so called clusters. In the first part, we introduce the concept of clusters for
static graphs alongside their main properties. For dynamic graphs with time varying edge connections,
these cluster may be subject to change with every time step. Therefore additional characteristics
have to be introduced.

The second part describes two methods to detect, identify and track cluster in a dynamic graph.
A common solution for this problem is the clustering of a static graph at each time step, and the
identification of the same clusters over multiple time steps. A method is presented to track these
clusters, which is independent of the underlying static graph clustering algorithm.
Furthermore, we describe an extension of the k-clique percolation algorithm to dynamic graphs.

Finally, the clique percolation algorithm is applied to two different real world networks, which
yields interesting result about group dynamics, with regards to the correlation of various group
properties.
} % end of abstract


%% Uncomment below to include a (optional) teaser figure.
\teaser{ \centering
  \includegraphics[width=16cm]{images/CypressView}
  \caption{In den Wolken: Vancouver von Cypress Mountain. Auf der
    ersten Seite d"urfen keine Grafiken au"ser dieser optionalen
    Aufmachgrafik (Teaser) abgebildet sein.}
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%% START OF THE PAPER %%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

%% The ``\maketitle'' command must be the first command after the
%% ``\begin{document}'' command. It prepares and prints the title
%%   block.

%%   the only exception to this rule is the \firstsection command
\firstsection{Motivation}
\maketitle

  Das mathematische Konzept der Graphen ist ein essentielles 
  Modellierungswerkzeug in der Informatik. Nicht nur lassen sich damit
  verschiedenste Datenstrukturen anschaulich dargestellen, sondern
  mit ihrer Hilfe lassen sich auch jegliche Beziehungen zwischen einzelnen
  Objekten oder Prozessen in einem Netzwerk modellieren und untersuchen.
  Aus diesem Grund sind sie heutzutage nicht nur in der klassischen Informatik
  sowie in der Mathematik zu finden, sondern haben auch in vielen anderen
  Wissenschaften ihren Einzug erhalten. So werden sie genutzt um die
  Gruppendynamik in biologischen Netzwerken zu beschreiben, dienen
  als Kontrollalgorithmen für Multiagenten Systeme [?] und beschreiben
  Kommunikationsmuster in sozialen Netzwerken.
  
  Um die Eigenschaften sehr großer Netzwerke analytisch untersuchen zu können,
  werden häufig Zufallsgraphen nach dem Model von Edgar Gilbert (nachweise?) oder
  Erdos-Renyi verwendet. Diese Graphen haben die Besonderheit, dass die 
  Wahrscheinlichkeit für eine Verbindung zwischen je zwei Knoten im 
  gesammten Netzwerk konstant ist. Dadurch ensteht ein gleichmäßiger Graph,
  dessen Gradverteilung binomial verteilt sind, und somit die meisten Knoten 
  die gleiche Anzahl an Kanten haben. Mit Hilfe der Wahrscheinlichkeitstheorie,
  lassen sich nun die Eigenschaften dieser Graphen auch für eine sehr hohe Anzahl
  an Knoten bestimmen und untersuchen.
  
  Allerdings haben Untersuchungen von realen Netzen gezeigt (nachweis), dass sich
  diese in den meisten Fällen von Zufallsgraphen unterscheiden. Reale Netzwerke sind
  häufig sogenannte Skalenfreie Netze (im Englischen 'Scale-free networks'), in 
  denen die Anzahl der Verbindungen pro Knoten nicht binomial verteilt ist, sonder nach einem
  Potentzgesetz. Dadurch einsteht ein Netzwerk, in dem einzelne wenige Knoten eine große
  Anzahl an Verknüpfungen aufweisen, doch die Mehrzahl der Knoten weniger stark verknüpft ist. 
  Weiterhin ist die Kantenverteilung zwischen den Knoten auch lokal sehr inhomogen, so dass sich 
  Teilgraphen ausbilden, deren Knoten untereinander sehr stark bis komplett verknüpft sind,
  während sie nach Außen weniger Verbindungen aufweisen. Diese Teilgraphen werden auch 'Cluster' genannt.

  Diese Cluster spielen in viele Anwendungsgebieten eine wichtige Rolle. 
  Betrachtet man zum Beispiel den Graph der Freundschafts Beziehungen in einem sozialen Netzwerk,
  lassen sich mithilfe von Angaben anderer Benutzer, sowie lokaler Cluster, unter anderem Rückschlüße 
  auf gemeinsame Interessen, Wohnorte oder Freunde der einzelnen Benutzer schließen.
  Diese Informationen bieten dem soziale Marketing eine bis vor kurzem unbekannte Menge
  an Möglichkeiten ihre Produkte zielgerichteter und persönlicher zu vermarkten.
  Aber auch in dynamischen Graphen, in denen Knoten und Kanten sehr häufig wechseln können,
  ist es wichtig Cluster zu finden. Betrachtet man den Verbindungsgraph eines dezentralen, 
  kabellosen Ad-Hoc Netzwerks, so lassen sich mit Hilfe von Clustering Verfahren 
  Teilnetze finden die geographisch
  Eine zusätzliche Herrausforderung zur eigentlichen Clusteranalyse ist hierbei allerdings
  
  \subsection*{Übersicht}
  Diese Arbeit gibt einen Überblick über die Eigenschaften dieser Cluster, ihr

\section{Grundlagen}
  
  \subsection{Formale Definition eines Clustern}
  In diesem Kaptiel wird versucht eine formale Definition zu geben, was ein einen Cluster in Graphen zu. 
  Während die gewünschten Eigenschaften
  
  \subsubsection{Eigenschaften von Clustern}
  \label{sec:properties} 
  Der Artikel von S.E. Schaeffer [?] bietet eine umfassende Zusammenfassung
  über bisherige Clustering Verfahren, und versucht eine Defintion für 
  Cluster anhand gewünschter Eigenschafter zu geben.
  
  Betrachtet man den Teilgraphen $\Omega$ eines kompletten Graphen $\Upsilon$, so müssen
  mehrere Bedingungen erfüllt sein, damit $\Omega$ ein Cluster wird.
  Natürlich sollten alle Knoten aus $\Omega$ verbunden sein, was bedeutet das 
  zwischen jedem Paar aus Knoten $u$ und $v$ mit $u,v \in \Omega$ ein Pfad existiert. 
  Ist dies nicht der Fall so ist der gesammte Graph nicht verbunden, und das 
  Clustering sollte auf den einzelnen Teilgraphen gesondert betrachtet werden.
  Weiterhin sollte der Teilgraph $\Omega$ eine hohe Kantendichte zwischen seinen Knoten
  aufweisen. Dies ist der Fall, wenn mehere Pfade zwischen den Knoten aus $\Omega$ existieren,
  so dass jeder Pfad möglichst wenig Elemente aus $\Upsilon \setminus \Omega$ enthält.
  
  Der Grad $d(v)$ eines Knoten $v$ ist definiert als die Anzahl der Kanten zu anderen Knoten im
  Graphen $\Upsilon$. Ist nun $v \in \Omega$ wobei $\Omega$ wieder ein Teilgraph von $\Upsilon$
  ist, so lässt sich der Grad in einen externen und internen Teil unterscheiden. Dabei
  ist der interne Grad die Anzahl der Kanten von $v$ zu anderen Knoten aus $\Omega$, der externe
  Grad die Anzahl der Kanten von $v$ zu allen anderen Knoten aus $\Upsilon \setminus \Omega$.
  Dabei gilt:
    \begin{align}
      d_{int}(v, \Omega) &= |\Gamma(v) \cap \Omega |\\
      d_{ext}(v, \Omega) &= |\Gamma(v) \cap (\Upsilon \setminus \Omega) | \\
      d(v) &= d_{int}(v, \Omega) + d_{ext}(v, \Omega)
    \end{align}
  wobei $\Gamma(v)$ die direkten Nachbarn von $v$ sind.
  Eine Eigenschaft, die den Teilgraphen $\Omega$ zu einem Cluster werden lässt, ist ein hohes
  Verhältniss von internem zu externem Grad für alle Knoten $v \in \Omega$, d.h. die Knoten eins 
  Cluster haben untereinander wesentlich mehr Verknüpfungen als zu den Knoten des restlichen Graphen.
   
  Eine weiteres Kriterium für die Qualität eines Clusters ist die sogenannte interne Clusterdichte.
  Die allgemeine Dichte eines Graphen $\Upsilon = (V,E)$ mit der Knotenmenge $V$ und der Kantenmenge
  $E$ ist definiert als das Verhältniss der Summer aller Kanten durch die Anzahl aller 
  möglichen Kanten in Graph:
    \begin{align}
      \rho(\Upsilon) = \frac{|E|}{\binom{|V|}{2}} = \frac{2|E|}{|V|(|V|-1)}
    \end{align}
  Somit lässt sich die interne Clusterdichte eines Clusters $\Omega$ definieren als
    \begin{align}
      \rho_{int}(\Omega) = \frac{|\{\{u,v\} |u,v \in \Omega \}|}{|\Omega|(|\Omega|-1)}
    \end{align}
  wobei $\{u,v\}$ eine Kante zwischen den Knoten $u$ und $v$ darstellt. Die fehlende 2 im Z"ahler
  im Vergleich zur allgmeinen Graphendichte ist dadurch zu erklären, dass $\{u,v\}$ und $\{v,u\}$ 
  zwar die gleiche Kante darstellen, aber zwei unterschiedliche Elemente sind, wodurch die Anzahl
  der Kanten in $\{\{u,v\} |u,v \in \Omega \}$ verdoppelt wird.
  
  Zusätzlich zur internen Clusterdichte, existert noch eine sogenannte externe Clusterdichte 
  zwischen verschiedenen Clustern $\Omega_i$ eines Graphen $\Upsilon$. Sie ist definiert als
  das Verhältniss der Summe aller Kanten zu der Summe aller möglichen Kanten zwischen den
  verschiedenen Clustern $\Omega_i$:
    \begin{align}
      \rho_{ext}(\Upsilon|\Omega_1 ... \Omega_k) = \frac{|\{\{v,u\} | v\in \Omega_i\, u \in \Omega_j, i \neq j\}|}
                                                        {|V|(|V|-1)-\sum\limits_{l=1}^k |\Omega_k|(|\Omega_k|-1)}
    \end{align}
  wobei $|\Omega_i|$ die Anzahl der Knoten des Teilgraphen $\Omega_i$ darstellt.
  Im Allgmeinen kann man sagen, dass für ein gutes Clustering auf einem Graph $\Upsilon$ gelten sollte:
    \begin{align}
      \rho_{int}(\Omega_i) > \rho(\Upsilon) > \rho_{ext}(\Upsilon|\Omega_1 ... \Omega_k) \\ 
      			\forall i=1...k \notag
    \end{align}
  
  Abb.~\ref{fig:comp_cluster} zeigt drei verschiedene Cluster unterschiedlicher Qualität im Vergleich.
  Dabei representieren die schwarz hervorgehobenen, beliebig gewählten Teilgraphen jeweils 
  einen Cluster. Der linke Cluster weist eine sehr hohe intere
  Dichte auf, und hat kaum Kanten mit Knoten ausserhalb. Daher ist Qualität dieses Clusters
  sehr hoch. Der mittlere Cluster hat zwar die gleiche Anzahl an internen Kanten, weist
  aber im Gegensatz zum Linken eine wesentliche höhere Kantenanzahl zu Knoten ausserhalb des
  Cluster auf. Zwar hat der rechte Cluster nur wenige Kanten nach aussen, allerdings ist aber
  die Kantendichte innerhalb des Clusters minimalst, was ihn zum schlechtesten Cluster der drei macht.

  \begin{figure}[h]
    \centering
    \includegraphics[width=1.5in]{images/good_cluster}
    \caption{\label{fig:comp_cluster} Drei verschiedene Cluster unterschiedlicher Qualität [referenz]}
  \end{figure}
  
  \subsubsection{k-Cliques}
  \label{sec:k_cliques}
  	Einen Teilgraphen $\Omega$ mit $k$ Knoten nennt man $k$-Clique, falls alle $k$ Knoten dieses 
  	Teilgraphen direkt miteinander verbunden sind, und $\Omega$ somit vollst"andig ist. 
  	Die entstehende Topologie des Teilgraphen $\Omega$ ist natürlich vom Parameter $k$ abh"anging.
  	Abb. \ref{fig:k_cliques} zeigt k-Cliques f"ur verschiedene Werte von $k$.
  	
  	\begin{figure}[h]
  	 \centering
  	 \includegraphics[width=2in]{images/k-cliques-example}
  	 \caption{\label{fig:k_cliques} Topologien f"ur k-Cliques mit k=2,3,4,5}
  	\end{figure}

  	
  	Da jede k-Clique vollst"andig ist, ist die in Kapitel \ref{sec:properties} definierte
  	interne Graphdichte mit $\rho_{int}(\Omega)=1$ maximal. Somit stellen k-Cliques theoretisch gute 
  	Kandidaten f"uer Cluster da. Beschr"ankt man sich bei der Clusterfindung auf einzelne k-Cliques,
  	werden in den meisten F"allen viele Cluster nicht gefunden, da Forderung an einen vollst"andig
  	verknupften Cluster zu restrektiv ist.
    
  \subsection{Dynamische Graphen}
	Ein klassicher Graph $\Omega=(V,E)$ ist eine Kombination einer Menge an Knoten $V$ und
	Kanten $E$ zu einem bestimmten Zeitpunkt $t$. F"ur viele Anwendungen
	ist es aber essentiell das Netzwerk "uber einen Zeitraum mit mehreren Zeitschritten $t_i$ zu
	betrachten und untersuchen.
	
	Das Konzept der \emph{dynamischen Graphen}[Quelle] stellt die zeitliche Ver"anderung eines Graphen
	als geordnete Folge von statischen Teilgraphen f"ur jeden Zeitpunkt $t=1,...,n$ da:
	\begin{align}
		\Upsilon=\{\Omega_1=(V_1, E_1), \Omega_2=(V_2, E_2), ..., \Omega_n=(V_n,E_n)\}
	\end{align}
	wobei $\Omega_i$ der Konfiguration des dynamischen Graphen $\Upsilon$ zum Zeitpunkt $i$ entspricht.
	Da alle $V_i, E_i$ f"ur alle Werte von $i$ unabh"angig sind, ist es m"ogich das zu jedem Zeitschritt
	sowohl Kanten als auch Knoten hinzugef"ugt oder verschwinden k"onnen.
  
\section{Clustering in statischen Graphen}



  Viele Clustering Verfahren f"ur dynamische Graphen basieren auf Verfahren zur Clusterung klassischer,
  statischer Graphen. Da dynamische Graphen aufgrund der Zeitanh"angigkeit weitere Komplexit"at einf"uhren,
  ist es sinnvoll als erstes diese Clusteringmethoden f"ur statische Graphen zu betrachten.
  In diesem Kaptiel wird versucht die Vielzahl verschiedener Verfahren anhand ihrer grunds"atzlichen Eigenschaften
  in verschiedene Kategorien zu klassifizieren, sowie eine kurze Erkl"arung ihrer Funktionsweise zu geben.
  
  Nach Schaeffer[] lassen sich Clustering Verfahren grunds"atzlich in lokale oder globale
  Verfahren einteilen. Hierbei werden die Verfahren entweder global auf den ganzen Graph angewendet,
  oder nur lokal auf einen Teilgraphen. Entsprechend ben"otigen globale Verfahren Informationen "ueber 
  die Topologie des gesammten Graphen, w"ahrend bei bei lokalen Verfahren nur rekursiv die Nachbarschaft
  eines einzelnen Knotens betrachtet wird, somit auch Netzwerke betrachtet werden k"onnen, die a priori
  nicht komplett bestimmt sind.
  
  Entsprechend bieten lokale Verfahren eine bessere Skalierbarkeit als Globale, falls das Clustering nur
  auf einen Teilgraphen angewendet werden soll, da die Topologie des restlichen Graphen nicht bekannt sein muss.
  Weiterhin haben diese Verfahren den Vorteil, dass das Clustering nur von der lokalen Struktur anh"angt und eine
  lokale "Anderung im Graphen auch nur das Clusterung in deren Umgebung beeinflusst. Deshalb eignen sich lokale
  Verfahren in Anwendungen, bei denen die Nachbarschaft einzelner Knoten schnell und h"aufig untersucht werden soll.
  
  
    \begin{table}[h]
    %% Table captions on top in journal version
    \caption{\label{tab:static_methods} Einteilung der Clusteringverfahren f"ur statische Graphen}
    \scriptsize
    \begin{center}
      \begin{tabular}{c|l|c}
	& Globale Verfahren & Lokale Verfahren\\
	\hline
	Top-Down  & Spektrale Methoden       & \\
	          & Random Walk Methoden     & \\
	          & Maximaler Fluss Methoden & \\
	\hline
	Bottom-Up & Modularit"atsoptimierung & CPM \\
	          & N"achste Nachbarn Methode & 
      \end{tabular}
    \end{center}
  \end{table}
  
  \subsubsection*{Globale Verfahren}
  Die Familie der globalen Verfahren l"asst sich noch mal in sogenannte \emph{Top-Down}, sowie
  \emph{Bottom-Up} Methoden[Schaeffer] unterteilen. Bei Top-Down Verfahren wird der Graph rekursiv anhand
  verschiedener Kriterien in immer kleinere Methoden unterteilt, w"ahrend bei Bottom-Up Verfahren
  viele kleinere Cluster sukzessive zu gr"osseren zusammen gefasst werden, bis das Clustering einem
  Abbruchkriterum gen"ugt.
  
  Ein Vertreter der Top-Down Methoden, sind die sogenannten \emph{Spektralen Methoden}. Sie basieren auf den
  Eigenwerten und Vektoren der Laplace-Matrix des Graphen. Die Laplace Matrix eines Graph
  $\Omega=(V,E)$ ist definert als
  \begin{align}
    L(\Omega)&=D(\Omega)-A(\Omega)
  \end{align}
  wobei $D(\Omega)=diag(\{d(v_1), ..., d(v_n)\})$ die Degreematrix von $\Omega$ ist[Buch "ueber graph theorie].
  $A(\Omega)$ ist die sogenannte Adjacency Matrix von $\Omega$, und definiert als
  \begin{align}
   \left[A\right]_{ij}&= \begin{cases}
			    1 & \text{falls zwischen }v_i\text{ und }v_j\text{ eine Kante besteht}\\
			    0 & \text{sonst}
			  \end{cases}
  \end{align}
  Da die Laplace Matrix eine symmetrische, positiv semidefinite Matrix ist[Buch], sind alle Eigenwerte $\lambda_i \ge 0$
  und die korrespondierenden Eigenvektoren bilden ein orthogonales System. Ordnet man die Eigenwerte in
  aufsteigener Reihenfolge $\lambda_1 \le \lambda_2 \le \dots \le \lambda_n$, so folgt aus der positiv Semidefinitheit
  von L dass $\lambda_1 = 0$. Ist weiterhin $\lambda_2 > 0$ so exisitieren keine isolierten Teilgraphen im kompletten
  Graph[Buch]. Die Algorithmen der spektralen Clustering Methoden benutzen typischerweise die Komponenten des Fiedler
  Vektors -den Eigenvektor von $\lambda_2$- um die Knoten eins Graphen zu vergleichen und clustern[Schaeffer].

  Ein weitere Gruppe von Methoden die den Top-Down Ansatz verfolgen, sind die sogenannten \emph{Random Walk} oder
  \emph{Markov Ketten Methoden}. Diese Verfahren basieren auf einem zuf"alligen Weg $\xi$ fester L"ange durch den Graph.
  Dabei wird $\xi$, ausgehend von einem Startknoten $v_{start}$, iterativ "uber eine zuf"allige Auswahl
  der direkten Nachbarn des jeweils aktuellen Knoten aufgebaut. Aufgrund der h"oheren Dichte in Clustern, wird der Weg
  $\xi$ die Knoten des selben Clusters wie $v_{start}$ h"aufiger besuchen als Knoten ausserhalb des Clusters.
  Abb. \ref{fig:random_walk} zeigt einen Beispielgraph mit zwei Clustern. Wird ein Weg ausgehend von einem weissen
  Knoten aufgebaut, ist es f"ur einen zuf"alligen Weg nur auf einem Knoten m"oglich den linken Cluster zu verlassen,
  und somit werden die weissen Knoten des linken Clusters mit einer h"oheren Wahrscheinlichkeit besucht. 

    \begin{figure}[h]
    \centering
    \includegraphics[width=2in]{images/random_walk}
    \caption{\label{fig:random_walk} [Schaeffer]}
    \end{figure}
    
  F"ur gewichtete Graphen eignen sich auch die \emph{Maximaler Fluss Methoden} um ein Clustering duchzuf"uhren. Sie
  geh"oren ebenfalls zu der Gruppe der Top-Down Verfahren, und versuchen einen minimalen Schnitt[Schaeffer] des Graphen zu finden. 
  Dazu werden Str"omungsberechnungen auf dem Graphen durchgef"uhrt, wobei ein Fluss zwischen zwei Knoten nur "uber eine Verbindungskante bestehen kann.
  Da aufgrund des \emph{Minimum cut, maximum Flow Theorms} der Schnitt eins Graphen beim maximalen Fluss am geringsten ist, l"asst sich dieser "uber
  den maximalen Fluss auf den Kanten des Graphen finden. Flake et al.[Quelle] berechneten hierzu den Fluss mithilfe k"unstlich hinzugef"ugter
  Senken, und erzeugten daraus einen Minimum-cut Tree [Quelle] um das Clustering auf einem Graphen durchzuf"uhren.
  
  Beispiele f"ur Methoden, die einen Bottom-Up Ansatz werden sind unter anderem die \emph{Modularit"atsoptimierung} welche
  in Kaptiel \ref{sec:modularity} genauer behandelt wird. Eine weitere Vertreter ist die sogenannte \emph{N"achste Nachbarn Methode}[Schaeffer], welche
  h"aufig auch bei allgmeinen Klassifizierungsproblmen angewendet wird. Um die N"achste Nachbarn Methode auf Graphen anwenden
  zu k"onnen, muss eine "Ahnlichkeit zwischen zwei Knoten definiert werden. Eine solche "Ahnlichkeit
  kann z.B. anhand von vorhandenen Metadaten jedes Knoten erfolgen, oder anhand der Schnittmenge der direkten Nachbarn zweier
  Knoten. Im ersten Schritt wird f"uer jeden Knoten des Graphen derjenige Nachbar gesucht, f"uer welchen die "Ahnlichkeit am gr"ossten ist.
  Diese beiden Knoten bilden nun einen Cluster. In den darauffolgenden Schritten, werden nun die bereits gefunden Cluster auf "Ahnlichkeit
  untersucht, und zu gr"osseren Cluster zusammengef"ugt, bis das Clustering beendet ist.
  
  
  \subsection{Modularit"atsoptimierung}
    \label{sec:modularity}
    Das Verfahren der Modularit"atsoptimierung ist ein weiterer Vertreter der Bottom-Up Ans"atze. Es versucht eine Paritionierung
    des Graphen zu finden, f"ur die die Modularit"at maximal wird. Hierbei ist die Modularit"at ein Ma"s, in wie fern die gew"ahlte
    Partitionierung $C(\Omega)$ eines Graphen $\Omega$ einem guten Clustering entspricht. Gesucht ist somit eine optimale Paritionierung welche dem Clustering des Graphen entspricht.
    Mathematisch ist die Modularit"at $Q(C)$ definiert als[paper]:
    \begin{align}
      Q(C)=\frac{1}{2|E|}\sum\limits_{u,v \in V}\left[ A_{uv} - \frac {k_vk_u}{2|E|}\delta \left( c(u), c(v)\right) \right]
    \end{align}
    wobei $A_{uv}=1$ falls eine Kannte zwischen $u$ und $v$ existiert, ansonsten 0. $k_u = d(u)$ ist der Grad des Knoten, und
    $c(u)$ diejenige Parition die den Knoten $u$ enthält. Weiterhin ist $\delta \left(c(u),c(v)\right)$ falls $c(u)=c(v)$,
    ansonsten 0.
    Somit representiert die Modularit"at die Summe aller Kanten innerhalb einer Partition minus der Anzahl der Kanten, falls diese 
    zuf"allig verteilt w"aren.
    
    Der trivialste Ansatz diejenige Partitionierung $C(\Omega)$ zu finden welche die Modularit"at maximiert, w"are die Berechnung
    aller m"oglichen Partitionen und ihrer dazugeh"origien Modularit"at. Es ist aber offensichtlich, dass bei steigender 
    Graphgr"osse die Anzahl m"oglicher Partitionen rasant steigt. Weiterhin wurde gezeigt[Quelle], dass das Problem
    eine optimale Partition zu finden NP-Vollst"andig ist.
    
    Eine optimale Partitionierung, und somit ein Clustering kann mithilfe der Heuristik in [] approximiert werden. Der wesentliche Bestandteil
    der Heuristik ist die Tatsache, das die "Anderung der Modularit"at $\Delta Q$, falls ein Knoten $v_i$ in den Cluster $C$ verschoben
    wird, lokal effizient berechnet werden kann:
    \begin{align}
     \Delta Q &= \left[ \frac{\sum_{in}+k_{i,in}}{2m} - \left( \frac{\sum_{tot}+k_i}{2m} \right)^2 \right] -
     \left[ \frac{\sum_{in}}{2m} - \left( \frac{\sum_{tot}}{2m} \right)^2 - \left( \frac{k_i}{2m} \right)^2 \right]
    \end{align}
    wobei $\sum_{in}$ die Summe der Gewichte aller Kanten des Clusters $C$ ist, $\sum_{tot}$ die Summe der Gewichte aller Kanten welche
    mit Knoten des Cluster $C$ verbunden sind, $k_i$ ist die Summe der Gewichte aller Kanten des Knoten $v_i$, $k_{i,in}$ ist die
    Summe der Gewichte aller Kanten welche den Knoten $i$ mit Knoten aus $C$ verbinden, und $m$ die Anzahl aller Kanten im Graph.
    Hierbei bleibt zu erw"ahnen, das sogenannte \emph{Selfloops}, also Kanten von $v_i$ nach $v_i$ erlaubt sind, und sogar
    ein wesentlicher Teil der Heuristik darstellen.
    
    Die Heuristik l"auft nun wie folgt ab:
    \begin{enumerate}
      \item F"ur jeden Knoten wird ein einzelner Cluster erstellt, der nur diesen einen Knoten enth"alt
      \item Berechnung der $\Delta Q$ f"ur das Verschieben eines Knoten $v_i$ in die Cluster seiner 
      		direkten Nachbarn. Anschlie"send wird $v_i$ in den Cluster desjenigen Nachbarn $v_j$ verschoben,
      		dessen $\Delta Q$ am gr"ossten ist. Ist die Zunahme der Modularit"at f"ur jeden Nachbarn negativ,
      		so bleibt der Knoten $v_i$ in seinem Cluster. Dieser Schritt wird solange wiederholt, bis sich
      		ein lokales Maxima der Modularit"at einstellt. Dabei ist es durchaus m"oglich das ein Knoten
      		mehrmals betrachtet wird.
      \item Ist ein lokales Maxima erreicht, wird einer neuer Graph aufgebaut. Dabei entsprechen die bisherigen
      		Cluster den Knoten des neuen Graph. Diese sind verbunden falls mindestens eine Kante zwischen
      		je einem Knoten der beiden Cluster existiert und das Gewicht dieser Kante ist die Summer
      		der Gewichte aller Kanten zwischen diesen Clustern. Kanten innerhalb eines Cluster f"uhren zu einem
      		Selfloop dessen Gewicht die Summer der Gewichte dieser Kanten ist. 
      \item F"uhre Schritte 1-3 wiederrum auf den neuen Graph aus, solange bis die Modularit"at nicht
      		weiter erh"oht werden kann.
    \end{enumerate}
    
  \subsection{Clique Percolation Method (CPM)}
    \label{sec:CPM}
    Alle bisher vorgestellten Methoden waren globale Clusteringverfahren. Ein lokales Verfahren ist die
    \emph{Clique Percolation Method (CPM)}, welche auf den in Kap. \ref{sec:k_cliques}
    vorgestellten k-Cliques beruht. Hierzu wird eine Nachbarschaftsbeziehung zwischen k-Cliques definiert, 
    bei der zwei k-Cliques benachbart sind, falls diese sich $k-1$ Knoten teilen. 
    
    Die CPM wird f"ur ein vorher festgelegtes $k$ durchgef"uhrt. Ein dabei gefundener Cluster
	entspricht der Menge der benachbarten Cliques der Gr"osse $k$.
    
    Abb. \ref{fig:CPM} zeigt die gefundenen Cluster einer CPM f"ur 3-Cliques in willk"urlichen Graphen.
    \begin{figure}[h]
     \centering
     \includegraphics[width=2in]{images/k-cliques}
     \caption{\label{fig:CPM} aus paper}
    \end{figure}


\section{Clustering in dynamischen Graphen}
  \subsection{Evolution eins Clusters}
    \begin{figure*}[h]
      \centering
      \includegraphics[width=10cm]{images/evolution_alone}\hfill

      \caption{Illustration "uber beide Textspalten hinweg. Auch
	Illustrationen m"ussen entsprechend den Quellen gekennzeichnet
	werden. \cite{strengert2006spectral}}
      \label{fig:evolution}
    \end{figure*}
  \subsection{Erweiterung der CPM}
  \subsection{Time step Clustering}

\section{maybe visualization of dynamic graphs}
  
\section{Group Evolution (results)}
 
\section{Conclusion}


\subsection{Abbildungen und Tabellen}

Alle Abbildungen (siehe Abb.\ \ref{fig:sample}) und Tabellen (Tabelle\
\ref{tab:vis_accept}) sollten zentriert sein
(\verb|\centering|). Abbildungen "uber beide Textspalten
(Abb. \ref{fig:multicolumn}) k"onnen mit
\verb|\begin{figure*}|\ldots\verb|\end{figure*}| eingef"ugt werden.

\subsection{Referenzen}

Literaturangaben wie beispielsweise Levoy \cite{levoy:1989:DSV} werden
mit Hilfe von BibTeX erzeugt. Dazu werden die Referenzen in die
Literaturliste (hier \emph{literatur.bib}) eingetragen und
entsprechend mit \verb|\cite| referenziert.

\subsection{\LaTeX-"Ubersetzung}

Die \LaTeX-Datei kann mit \emph{latex} oder \emph{pdflatex} "ubersetzt
werden. Dabei ist zu beachten, dass f"ur die "Ubersetzung mit
\emph{latex} die Grafiken in Postscript (eps) vorliegen, f"ur
\emph{pdflatex} entsprechend als jpg, png oder pdf.  Der Ablauf ist
dabei der folgende:
\begin{enumerate}
\item \verb|pdflatex <quelldatei.tex>|
\item \verb|bibtex <quelldatei>|
\item \verb|pdflatex <quelldatei.tex>| (evtl. mehrfach)
\end{enumerate}
Alternativ kann auch das mitgelieferte Makefile verwendet werden.









\bibliographystyle{abbrv}
%% use following if all content of bibtex file should be shown
% \nocite{*}
\bibliography{literatur}
\end{document}
